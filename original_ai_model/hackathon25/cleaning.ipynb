{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bead9c3",
   "metadata": {},
   "source": [
    "# Safetruck Malaysia — Data Cleaning and Feature Engineering\n",
    "\n",
    "This notebook implements the complete data cleaning pipeline according to the plan, including:\n",
    "1. Data ingestion and normalization\n",
    "2. GPS smoothing and filtering\n",
    "3. Odometer processing and fusion\n",
    "4. Trip segmentation\n",
    "5. Feature calculation\n",
    "6. Daily aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b85c9e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6effc083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For distance calculations\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd168aa3",
   "metadata": {},
   "source": [
    "## 2. Load and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2b65f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,358,738 rows\n",
      "\n",
      "Original columns: ['Timestamp', 'Latitude', 'Longitude', 'Speed', 'FuelLevelPercentage', 'FuelLevelLitre', 'EngineStatus', 'Direction', 'BatteryVoltage', 'Odometer', 'GPSLocated', 'CarNumberPlate', 'source_file']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Speed</th>\n",
       "      <th>FuelLevelPercentage</th>\n",
       "      <th>FuelLevelLitre</th>\n",
       "      <th>EngineStatus</th>\n",
       "      <th>Direction</th>\n",
       "      <th>BatteryVoltage</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>GPSLocated</th>\n",
       "      <th>CarNumberPlate</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01 00:01:05</td>\n",
       "      <td>3.48955</td>\n",
       "      <td>101.191783</td>\n",
       "      <td>0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>24.187</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>25.42</td>\n",
       "      <td>846477.374</td>\n",
       "      <td>True</td>\n",
       "      <td>ABA3768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-01 00:03:05</td>\n",
       "      <td>3.48955</td>\n",
       "      <td>101.191783</td>\n",
       "      <td>0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>24.187</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>25.41</td>\n",
       "      <td>846477.374</td>\n",
       "      <td>True</td>\n",
       "      <td>ABA3768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-01 00:05:04</td>\n",
       "      <td>3.48955</td>\n",
       "      <td>101.191783</td>\n",
       "      <td>0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>24.187</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>25.41</td>\n",
       "      <td>846477.374</td>\n",
       "      <td>True</td>\n",
       "      <td>ABA3768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-01 00:07:05</td>\n",
       "      <td>3.48955</td>\n",
       "      <td>101.191783</td>\n",
       "      <td>0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>24.187</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>25.41</td>\n",
       "      <td>846477.374</td>\n",
       "      <td>True</td>\n",
       "      <td>ABA3768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-01 00:09:05</td>\n",
       "      <td>3.48955</td>\n",
       "      <td>101.191783</td>\n",
       "      <td>0</td>\n",
       "      <td>25.46</td>\n",
       "      <td>24.187</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>25.41</td>\n",
       "      <td>846477.374</td>\n",
       "      <td>True</td>\n",
       "      <td>ABA3768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  Latitude   Longitude  Speed  FuelLevelPercentage  \\\n",
       "0  2025-08-01 00:01:05   3.48955  101.191783      0                25.46   \n",
       "1  2025-08-01 00:03:05   3.48955  101.191783      0                25.46   \n",
       "2  2025-08-01 00:05:04   3.48955  101.191783      0                25.46   \n",
       "3  2025-08-01 00:07:05   3.48955  101.191783      0                25.46   \n",
       "4  2025-08-01 00:09:05   3.48955  101.191783      0                25.46   \n",
       "\n",
       "   FuelLevelLitre  EngineStatus  Direction  BatteryVoltage    Odometer  \\\n",
       "0          24.187         False        269           25.42  846477.374   \n",
       "1          24.187         False        269           25.41  846477.374   \n",
       "2          24.187         False        269           25.41  846477.374   \n",
       "3          24.187         False        269           25.41  846477.374   \n",
       "4          24.187         False        269           25.41  846477.374   \n",
       "\n",
       "   GPSLocated CarNumberPlate source_file  \n",
       "0        True        ABA3768         NaN  \n",
       "1        True        ABA3768         NaN  \n",
       "2        True        ABA3768         NaN  \n",
       "3        True        ABA3768         NaN  \n",
       "4        True        ABA3768         NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the combined data\n",
    "data_path = 'data/Safetruck Hackathon Data/combined_data.csv'\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"\\nOriginal columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39b7a0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column mapping:\n",
      "  Timestamp -> timestamp_utc\n",
      "  Latitude -> lat\n",
      "  Longitude -> lon\n",
      "  Speed -> speed_kmh\n",
      "  EngineStatus -> engine_on\n",
      "  Odometer -> odometer_km\n",
      "  GPSLocated -> gps_ok\n",
      "  CarNumberPlate -> vehicle_id\n",
      "\n",
      "New columns: ['timestamp_utc', 'lat', 'lon', 'speed_kmh', 'FuelLevelPercentage', 'FuelLevelLitre', 'engine_on', 'Direction', 'BatteryVoltage', 'odometer_km', 'gps_ok', 'vehicle_id', 'source_file']\n"
     ]
    }
   ],
   "source": [
    "# Normalize column names to canonical schema\n",
    "# We need to inspect the actual columns first - let's create a flexible mapping\n",
    "\n",
    "column_mapping = {}\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'time' in col_lower or 'date' in col_lower:\n",
    "        column_mapping[col] = 'timestamp_utc'\n",
    "    elif 'plate' in col_lower or 'vehicle' in col_lower or 'asset' in col_lower:\n",
    "        column_mapping[col] = 'vehicle_id'\n",
    "    elif 'engine' in col_lower or 'ignition' in col_lower:\n",
    "        column_mapping[col] = 'engine_on'\n",
    "    elif 'speed' in col_lower:\n",
    "        column_mapping[col] = 'speed_kmh'\n",
    "    elif 'odometer' in col_lower or 'odo' in col_lower:\n",
    "        column_mapping[col] = 'odometer_km'\n",
    "    elif 'lat' in col_lower and 'lon' not in col_lower:\n",
    "        column_mapping[col] = 'lat'\n",
    "    elif 'lon' in col_lower or 'lng' in col_lower:\n",
    "        column_mapping[col] = 'lon'\n",
    "    elif 'gps' in col_lower and 'locat' in col_lower:\n",
    "        column_mapping[col] = 'gps_ok'\n",
    "\n",
    "print(\"Column mapping:\")\n",
    "for old, new in column_mapping.items():\n",
    "    print(f\"  {old} -> {new}\")\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "print(f\"\\nNew columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c2ea981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 265,586 duplicate rows\n",
      "\n",
      "Final shape: (2093152, 13)\n",
      "Date range: 2025-08-01 00:00:01+00:00 to 2025-08-31 23:59:53+00:00\n",
      "Number of vehicles: 31\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2093152 entries, 0 to 2093151\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Dtype              \n",
      "---  ------               -----              \n",
      " 0   timestamp_utc        datetime64[ns, UTC]\n",
      " 1   lat                  float64            \n",
      " 2   lon                  float64            \n",
      " 3   speed_kmh            int64              \n",
      " 4   FuelLevelPercentage  float64            \n",
      " 5   FuelLevelLitre       float64            \n",
      " 6   engine_on            bool               \n",
      " 7   Direction            int64              \n",
      " 8   BatteryVoltage       float64            \n",
      " 9   odometer_km          float64            \n",
      " 10  gps_ok               bool               \n",
      " 11  vehicle_id           object             \n",
      " 12  source_file          object             \n",
      "dtypes: bool(2), datetime64[ns, UTC](1), float64(6), int64(2), object(2)\n",
      "memory usage: 179.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Parse timestamps to UTC\n",
    "df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'], utc=True, errors='coerce')\n",
    "\n",
    "# Sort by vehicle and timestamp\n",
    "df.sort_values(['vehicle_id', 'timestamp_utc'], inplace=True)\n",
    "\n",
    "# Drop exact duplicates\n",
    "initial_count = len(df)\n",
    "df.drop_duplicates(subset=['vehicle_id', 'timestamp_utc'], keep='first', inplace=True)\n",
    "print(f\"Dropped {initial_count - len(df):,} duplicate rows\")\n",
    "\n",
    "# Coerce numeric columns\n",
    "numeric_cols = ['speed_kmh', 'odometer_km', 'lat', 'lon']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convert engine_on to boolean\n",
    "if 'engine_on' in df.columns:\n",
    "    df['engine_on'] = df['engine_on'].astype(bool)\n",
    "\n",
    "# Convert gps_ok to boolean\n",
    "if 'gps_ok' in df.columns:\n",
    "    df['gps_ok'] = df['gps_ok'].astype(bool)\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"\\nFinal shape: {df.shape}\")\n",
    "print(f\"Date range: {df['timestamp_utc'].min()} to {df['timestamp_utc'].max()}\")\n",
    "print(f\"Number of vehicles: {df['vehicle_id'].nunique()}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce895c",
   "metadata": {},
   "source": [
    "## 3. GPS Smoothing and Step Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "555c5f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haversine function defined\n"
     ]
    }
   ],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    Returns distance in kilometers\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    \n",
    "    # Radius of earth in kilometers\n",
    "    r = 6371\n",
    "    \n",
    "    return c * r\n",
    "\n",
    "print(\"Haversine function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33493d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed smoothing applied\n",
      "Original speed range: 0.00 - 160.00 km/h\n",
      "Smoothed speed range: 0.00 - 126.00 km/h\n"
     ]
    }
   ],
   "source": [
    "# Apply rolling median smoothing to speed per vehicle\n",
    "df['speed_smoothed'] = df.groupby('vehicle_id')['speed_kmh'].transform(\n",
    "    lambda x: x.rolling(window=3, center=True, min_periods=1).median()\n",
    ")\n",
    "\n",
    "print(\"Speed smoothing applied\")\n",
    "print(f\"Original speed range: {df['speed_kmh'].min():.2f} - {df['speed_kmh'].max():.2f} km/h\")\n",
    "print(f\"Smoothed speed range: {df['speed_smoothed'].min():.2f} - {df['speed_smoothed'].max():.2f} km/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cc66218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPS steps calculated: 2,093,121 valid steps\n",
      "Mean GPS step: 167.3835 km\n",
      "Median GPS step: 0.2796 km\n"
     ]
    }
   ],
   "source": [
    "# Compute GPS step distance and time delta per vehicle\n",
    "df['lat_prev'] = df.groupby('vehicle_id')['lat'].shift(1)\n",
    "df['lon_prev'] = df.groupby('vehicle_id')['lon'].shift(1)\n",
    "df['time_prev'] = df.groupby('vehicle_id')['timestamp_utc'].shift(1)\n",
    "\n",
    "# Calculate GPS step distance using haversine\n",
    "mask = df['lat'].notna() & df['lon'].notna() & df['lat_prev'].notna() & df['lon_prev'].notna()\n",
    "df.loc[mask, 'gps_step_km'] = df.loc[mask].apply(\n",
    "    lambda row: haversine(row['lat_prev'], row['lon_prev'], row['lat'], row['lon']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate time delta in hours\n",
    "df['time_delta_hours'] = (df['timestamp_utc'] - df['time_prev']).dt.total_seconds() / 3600\n",
    "\n",
    "print(f\"GPS steps calculated: {df['gps_step_km'].notna().sum():,} valid steps\")\n",
    "print(f\"Mean GPS step: {df['gps_step_km'].mean():.4f} km\")\n",
    "print(f\"Median GPS step: {df['gps_step_km'].median():.4f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9fae30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalidated 54,695 GPS steps where gps_ok=False\n",
      "Filtered 880,342 teleport/spike events (>140 km/h)\n",
      "Valid GPS steps remaining: 1,184,201\n"
     ]
    }
   ],
   "source": [
    "# Filter teleports and spikes\n",
    "# If implied speed > 140 km/h, mark as invalid\n",
    "df['implied_speed_kmh'] = np.where(\n",
    "    df['time_delta_hours'] > 0,\n",
    "    df['gps_step_km'] / df['time_delta_hours'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Mark teleports\n",
    "teleport_mask = df['implied_speed_kmh'] > 140\n",
    "teleport_count = teleport_mask.sum()\n",
    "\n",
    "# Set gps_step_km to NaN for teleports\n",
    "df.loc[teleport_mask, 'gps_step_km'] = np.nan\n",
    "\n",
    "# If gps_ok is False, also set gps_step_km to NaN\n",
    "if 'gps_ok' in df.columns:\n",
    "    bad_gps_mask = df['gps_ok'] == False\n",
    "    df.loc[bad_gps_mask, 'gps_step_km'] = np.nan\n",
    "    print(f\"Invalidated {bad_gps_mask.sum():,} GPS steps where gps_ok=False\")\n",
    "\n",
    "print(f\"Filtered {teleport_count:,} teleport/spike events (>140 km/h)\")\n",
    "print(f\"Valid GPS steps remaining: {df['gps_step_km'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dad0ad",
   "metadata": {},
   "source": [
    "## 4. Odometer Deltas and Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67382a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odometer steps calculated: 2,093,121\n",
      "Invalid odometer steps: 882,130\n",
      "  - Negative: 442,017\n",
      "  - Large delta: 440,113\n"
     ]
    }
   ],
   "source": [
    "# Compute odometer step per vehicle\n",
    "df['odo_step_km'] = df.groupby('vehicle_id')['odometer_km'].diff()\n",
    "\n",
    "# Mark invalid odometer steps\n",
    "# Negative deltas or unrealistically large deltas (> 50 km in < 60s)\n",
    "df['invalid_odo_step'] = False\n",
    "\n",
    "# Negative deltas\n",
    "negative_mask = df['odo_step_km'] < 0\n",
    "df.loc[negative_mask, 'invalid_odo_step'] = True\n",
    "\n",
    "# Large deltas in short time\n",
    "large_delta_mask = (df['odo_step_km'] > 50) & (df['time_delta_hours'] < (60/3600))\n",
    "df.loc[large_delta_mask, 'invalid_odo_step'] = True\n",
    "\n",
    "print(f\"Odometer steps calculated: {df['odo_step_km'].notna().sum():,}\")\n",
    "print(f\"Invalid odometer steps: {df['invalid_odo_step'].sum():,}\")\n",
    "print(f\"  - Negative: {negative_mask.sum():,}\")\n",
    "print(f\"  - Large delta: {large_delta_mask.sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44ab5ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration segments used: 552,061\n",
      "Vehicles with scale factors: 31\n",
      "\n",
      "Scale factor statistics:\n",
      "count    31.000000\n",
      "mean      0.988548\n",
      "std       0.035287\n",
      "min       0.800000\n",
      "25%       0.994768\n",
      "50%       0.995748\n",
      "75%       0.996959\n",
      "max       0.998873\n",
      "Name: odo_gps_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate GPS-corrected odometer scale factor per vehicle\n",
    "# Use valid segments where:\n",
    "# - gps_ok == True\n",
    "# - gps_step_km is finite\n",
    "# - 0.01 <= odo_step_km <= 5.0\n",
    "# - implied_speed <= 120 km/h\n",
    "\n",
    "calibration_mask = (\n",
    "    (df['gps_ok'] == True) &\n",
    "    (df['gps_step_km'].notna()) &\n",
    "    (df['odo_step_km'] >= 0.01) &\n",
    "    (df['odo_step_km'] <= 5.0) &\n",
    "    (df['invalid_odo_step'] == False) &\n",
    "    (df['implied_speed_kmh'] <= 120)\n",
    ")\n",
    "\n",
    "df['odo_gps_ratio'] = np.where(\n",
    "    calibration_mask & (df['odo_step_km'] > 0),\n",
    "    df['gps_step_km'] / df['odo_step_km'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Calculate median scale factor per vehicle\n",
    "scale_factors = df[df['odo_gps_ratio'].notna()].groupby('vehicle_id')['odo_gps_ratio'].median()\n",
    "\n",
    "# Clip to reasonable range [0.8, 1.2]\n",
    "scale_factors = scale_factors.clip(0.8, 1.2)\n",
    "\n",
    "print(f\"Calibration segments used: {calibration_mask.sum():,}\")\n",
    "print(f\"Vehicles with scale factors: {len(scale_factors)}\")\n",
    "print(f\"\\nScale factor statistics:\")\n",
    "print(scale_factors.describe())\n",
    "\n",
    "# Map scale factors back to dataframe\n",
    "df['scale_factor'] = df['vehicle_id'].map(scale_factors).fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ebdab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused distance calculation:\n",
      "  - From odometer (scaled): 1,210,991\n",
      "  - From GPS: 7,214\n",
      "  - Missing: 874,947\n",
      "\n",
      "Total fused distance: 20,798,697.92 km\n",
      "Mean step: 9.9365 km\n",
      "Median step: 0.0000 km\n"
     ]
    }
   ],
   "source": [
    "# Create fused distance\n",
    "df['fused_step_km'] = 0.0\n",
    "df['distance_missing'] = False\n",
    "\n",
    "# Priority 1: Valid odometer (scaled)\n",
    "valid_odo_mask = (df['odo_step_km'].notna()) & (df['invalid_odo_step'] == False) & (df['odo_step_km'] >= 0)\n",
    "df.loc[valid_odo_mask, 'fused_step_km'] = df.loc[valid_odo_mask, 'odo_step_km'] * df.loc[valid_odo_mask, 'scale_factor']\n",
    "\n",
    "# Priority 2: Valid GPS (when odometer not available)\n",
    "valid_gps_mask = (~valid_odo_mask) & (df['gps_step_km'].notna())\n",
    "df.loc[valid_gps_mask, 'fused_step_km'] = df.loc[valid_gps_mask, 'gps_step_km']\n",
    "\n",
    "# Mark missing distance\n",
    "df['distance_missing'] = (df['fused_step_km'] == 0) & (df['odo_step_km'].isna() | (df['invalid_odo_step'] == True)) & (df['gps_step_km'].isna())\n",
    "\n",
    "print(f\"Fused distance calculation:\")\n",
    "print(f\"  - From odometer (scaled): {valid_odo_mask.sum():,}\")\n",
    "print(f\"  - From GPS: {valid_gps_mask.sum():,}\")\n",
    "print(f\"  - Missing: {df['distance_missing'].sum():,}\")\n",
    "print(f\"\\nTotal fused distance: {df['fused_step_km'].sum():,.2f} km\")\n",
    "print(f\"Mean step: {df['fused_step_km'].mean():.4f} km\")\n",
    "print(f\"Median step: {df['fused_step_km'].median():.4f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c398b7",
   "metadata": {},
   "source": [
    "## 5. Outlier Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c28ac604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier labeling completed:\n",
      "  - Flagged over 120 (bad GPS): 15\n",
      "  - Speeding over 120 (good GPS): 3\n",
      "  - Excluded from metrics: 15\n"
     ]
    }
   ],
   "source": [
    "# Create outlier flags\n",
    "df['flagged_over120'] = (df['gps_ok'] == False) & (df['speed_smoothed'] > 120)\n",
    "df['speeding_over120'] = (df['gps_ok'] == True) & (df['speed_smoothed'] > 120)\n",
    "\n",
    "# Exclusion policy: exclude flagged_over120 from metrics\n",
    "# For speeding_over120, we'll keep them but track separately (policy b)\n",
    "df['exclude_from_metrics'] = df['flagged_over120']\n",
    "\n",
    "print(\"Outlier labeling completed:\")\n",
    "print(f\"  - Flagged over 120 (bad GPS): {df['flagged_over120'].sum():,}\")\n",
    "print(f\"  - Speeding over 120 (good GPS): {df['speeding_over120'].sum():,}\")\n",
    "print(f\"  - Excluded from metrics: {df['exclude_from_metrics'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1b415",
   "metadata": {},
   "source": [
    "## 6. Trip Segmentation (Hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c25fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip segmentation completed\n",
      "Total trips identified: 142,782\n"
     ]
    }
   ],
   "source": [
    "# Initialize trip_id\n",
    "df['trip_id'] = 0\n",
    "\n",
    "# For each vehicle, segment trips\n",
    "for vehicle in df['vehicle_id'].unique():\n",
    "    vehicle_mask = df['vehicle_id'] == vehicle\n",
    "    vehicle_df = df[vehicle_mask].copy()\n",
    "    \n",
    "    trip_counter = 0\n",
    "    current_trip = trip_counter\n",
    "    \n",
    "    for i in range(len(vehicle_df)):\n",
    "        idx = vehicle_df.index[i]\n",
    "        \n",
    "        # First row starts a new trip\n",
    "        if i == 0:\n",
    "            df.loc[idx, 'trip_id'] = trip_counter\n",
    "            continue\n",
    "        \n",
    "        prev_idx = vehicle_df.index[i-1]\n",
    "        \n",
    "        # Check for trip segmentation conditions\n",
    "        new_trip = False\n",
    "        \n",
    "        # 1. Ignition change: False -> True\n",
    "        if df.loc[prev_idx, 'engine_on'] == False and df.loc[idx, 'engine_on'] == True:\n",
    "            new_trip = True\n",
    "        \n",
    "        # 2. Time gap >= 15 minutes\n",
    "        time_gap_minutes = (df.loc[idx, 'timestamp_utc'] - df.loc[prev_idx, 'timestamp_utc']).total_seconds() / 60\n",
    "        if time_gap_minutes >= 15:\n",
    "            new_trip = True\n",
    "        \n",
    "        # 3. Long idle period (>= 15 min with engine on but no movement)\n",
    "        # This requires looking at a window, simplified here\n",
    "        \n",
    "        if new_trip:\n",
    "            trip_counter += 1\n",
    "            current_trip = trip_counter\n",
    "        \n",
    "        df.loc[idx, 'trip_id'] = current_trip\n",
    "\n",
    "print(f\"Trip segmentation completed\")\n",
    "print(f\"Total trips identified: {df['trip_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbae5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique trip keys: 146,284\n",
      "Trips per vehicle statistics:\n",
      "count        31.000000\n",
      "mean       4718.838710\n",
      "std       25623.512131\n",
      "min          30.000000\n",
      "25%          73.000000\n",
      "50%         117.000000\n",
      "75%         156.500000\n",
      "max      142782.000000\n",
      "Name: trip_id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create unique trip identifier combining vehicle and trip\n",
    "df['trip_key'] = df['vehicle_id'].astype(str) + '_' + df['trip_id'].astype(str)\n",
    "\n",
    "print(f\"Unique trip keys: {df['trip_key'].nunique():,}\")\n",
    "print(f\"Trips per vehicle statistics:\")\n",
    "trips_per_vehicle = df.groupby('vehicle_id')['trip_id'].nunique()\n",
    "print(trips_per_vehicle.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db62fc",
   "metadata": {},
   "source": [
    "## 7. Trip-Level Feature Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cf4de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle and moving periods identified\n",
      "Idle periods: 674,822\n",
      "Moving periods: 861,596\n"
     ]
    }
   ],
   "source": [
    "# Calculate time delta in minutes for idle/moving calculations\n",
    "df['time_delta_min'] = df['time_delta_hours'] * 60\n",
    "\n",
    "# Mark idle periods (engine on, speed < 1 km/h)\n",
    "df['is_idle'] = (df['engine_on'] == True) & (df['speed_smoothed'] < 1)\n",
    "\n",
    "# Mark moving periods (engine on, speed >= 1 km/h)\n",
    "df['is_moving'] = (df['engine_on'] == True) & (df['speed_smoothed'] >= 1)\n",
    "\n",
    "print(\"Idle and moving periods identified\")\n",
    "print(f\"Idle periods: {df['is_idle'].sum():,}\")\n",
    "print(f\"Moving periods: {df['is_moving'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate trip-level features\n",
    "trip_features = []\n",
    "\n",
    "for trip_key in df['trip_key'].unique():\n",
    "    trip_data = df[df['trip_key'] == trip_key].copy()\n",
    "    \n",
    "    # Exclude flagged data points from calculations\n",
    "    valid_trip_data = trip_data[~trip_data['exclude_from_metrics']].copy()\n",
    "    \n",
    "    if len(valid_trip_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Basic trip info\n",
    "    vehicle_id = trip_data['vehicle_id'].iloc[0]\n",
    "    trip_id = trip_data['trip_id'].iloc[0]\n",
    "    \n",
    "    # Timestamps\n",
    "    trip_start_utc = valid_trip_data['timestamp_utc'].min()\n",
    "    trip_end_utc = valid_trip_data['timestamp_utc'].max()\n",
    "    trip_duration_min = (trip_end_utc - trip_start_utc).total_seconds() / 60\n",
    "    \n",
    "    # Distance\n",
    "    trip_distance_km = valid_trip_data['fused_step_km'].sum()\n",
    "    \n",
    "    # Idle and moving time\n",
    "    idle_time_min = valid_trip_data[valid_trip_data['is_idle']]['time_delta_min'].sum()\n",
    "    moving_time_min = valid_trip_data[valid_trip_data['is_moving']]['time_delta_min'].sum()\n",
    "    \n",
    "    # Average speed\n",
    "    avg_speed_kmh = (trip_distance_km / (trip_duration_min / 60)) if trip_duration_min > 0 else 0\n",
    "    \n",
    "    # Idle percentage\n",
    "    idle_percentage = (idle_time_min / trip_duration_min * 100) if trip_duration_min > 0 else 0\n",
    "    \n",
    "    # Speeding counts (include all data for KPI counts)\n",
    "    speeding_count = trip_data['speeding_over120'].sum()\n",
    "    flagged_count = trip_data['flagged_over120'].sum()\n",
    "    \n",
    "    trip_features.append({\n",
    "        'vehicle_id': vehicle_id,\n",
    "        'trip_id': trip_id,\n",
    "        'trip_key': trip_key,\n",
    "        'Trip_Start_UTC': trip_start_utc,\n",
    "        'Trip_End_UTC': trip_end_utc,\n",
    "        'Trip_Duration_min': trip_duration_min,\n",
    "        'Trip_Distance_km': trip_distance_km,\n",
    "        'Idle_Time_min': idle_time_min,\n",
    "        'Moving_Time_min': moving_time_min,\n",
    "        'Avg_Speed_kmh': avg_speed_kmh,\n",
    "        'Idle_Percentage': idle_percentage,\n",
    "        'Speeding_Count': speeding_count,\n",
    "        'Flagged_Count': flagged_count\n",
    "    })\n",
    "\n",
    "df_trips = pd.DataFrame(trip_features)\n",
    "\n",
    "print(f\"Trip features calculated for {len(df_trips):,} trips\")\n",
    "print(f\"\\nTrip statistics:\")\n",
    "print(df_trips[['Trip_Duration_min', 'Trip_Distance_km', 'Avg_Speed_kmh', 'Idle_Percentage']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter trips by validity criteria\n",
    "# Keep trips with duration >= 5 min AND distance >= 1 km\n",
    "df_trips_valid = df_trips[\n",
    "    (df_trips['Trip_Duration_min'] >= 5) & \n",
    "    (df_trips['Trip_Distance_km'] >= 1)\n",
    "].copy()\n",
    "\n",
    "print(f\"Valid trips after filtering: {len(df_trips_valid):,} (removed {len(df_trips) - len(df_trips_valid):,})\")\n",
    "print(f\"\\nValid trip statistics:\")\n",
    "print(df_trips_valid[['Trip_Duration_min', 'Trip_Distance_km', 'Avg_Speed_kmh', 'Idle_Percentage']].describe())\n",
    "\n",
    "df_trips_valid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c247a",
   "metadata": {},
   "source": [
    "## 8. Daily Aggregation (MYT Timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to MYT timezone (UTC+8)\n",
    "df_trips_valid['Trip_Start_MYT'] = df_trips_valid['Trip_Start_UTC'].dt.tz_convert('Asia/Kuala_Lumpur')\n",
    "df_trips_valid['date_myt'] = df_trips_valid['Trip_Start_MYT'].dt.date\n",
    "\n",
    "print(f\"Date range (MYT): {df_trips_valid['date_myt'].min()} to {df_trips_valid['date_myt'].max()}\")\n",
    "print(f\"Number of unique dates: {df_trips_valid['date_myt'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64afdf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate daily metrics per vehicle-day\n",
    "daily_agg = df_trips_valid.groupby(['vehicle_id', 'date_myt']).agg({\n",
    "    'Trip_Distance_km': 'sum',\n",
    "    'Trip_Duration_min': 'sum',\n",
    "    'Idle_Time_min': 'sum',\n",
    "    'Moving_Time_min': 'sum',\n",
    "    'trip_id': 'count',  # Trip count\n",
    "    'Speeding_Count': 'sum',\n",
    "    'Flagged_Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "daily_agg.rename(columns={\n",
    "    'Trip_Distance_km': 'Total_Distance_km',\n",
    "    'Trip_Duration_min': 'Total_Duration_min',\n",
    "    'Idle_Time_min': 'Total_Idle_min',\n",
    "    'Moving_Time_min': 'Total_Moving_min',\n",
    "    'trip_id': 'Trip_Count'\n",
    "}, inplace=True)\n",
    "\n",
    "# Calculate daily average speed and idle percentage\n",
    "daily_agg['Daily_Avg_Speed_kmh'] = daily_agg.apply(\n",
    "    lambda row: (row['Total_Distance_km'] / (row['Total_Duration_min'] / 60)) if row['Total_Duration_min'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "daily_agg['Daily_Idle_Percentage'] = daily_agg.apply(\n",
    "    lambda row: (row['Total_Idle_min'] / row['Total_Duration_min'] * 100) if row['Total_Duration_min'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_daily = daily_agg.copy()\n",
    "\n",
    "print(f\"Daily aggregates created for {len(df_daily):,} vehicle-days\")\n",
    "print(f\"\\nDaily statistics:\")\n",
    "print(df_daily[['Total_Distance_km', 'Total_Duration_min', 'Daily_Avg_Speed_kmh', 'Daily_Idle_Percentage', 'Trip_Count']].describe())\n",
    "\n",
    "df_daily.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa781e84",
   "metadata": {},
   "source": [
    "## 9. Validation and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e4ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency check: trip distance vs raw fused distance\n",
    "total_trip_distance = df_trips_valid['Trip_Distance_km'].sum()\n",
    "total_fused_distance = df[~df['exclude_from_metrics']]['fused_step_km'].sum()\n",
    "\n",
    "print(\"=== CONSISTENCY CHECKS ===\")\n",
    "print(f\"Total trip distance: {total_trip_distance:,.2f} km\")\n",
    "print(f\"Total fused distance (valid points): {total_fused_distance:,.2f} km\")\n",
    "print(f\"Difference: {abs(total_trip_distance - total_fused_distance):,.2f} km\")\n",
    "print(f\"Difference percentage: {abs(total_trip_distance - total_fused_distance) / total_fused_distance * 100:.2f}%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity band checks\n",
    "print(\"=== SANITY CHECKS ===\")\n",
    "print(f\"\\nAverage Speed Distribution:\")\n",
    "print(f\"  Typical range (20-90 km/h): {((df_trips_valid['Avg_Speed_kmh'] >= 20) & (df_trips_valid['Avg_Speed_kmh'] <= 90)).sum()} trips ({((df_trips_valid['Avg_Speed_kmh'] >= 20) & (df_trips_valid['Avg_Speed_kmh'] <= 90)).sum() / len(df_trips_valid) * 100:.1f}%)\")\n",
    "print(f\"  Below 20 km/h: {(df_trips_valid['Avg_Speed_kmh'] < 20).sum()} trips\")\n",
    "print(f\"  Above 90 km/h: {(df_trips_valid['Avg_Speed_kmh'] > 90).sum()} trips\")\n",
    "\n",
    "print(f\"\\nIdle Percentage Distribution:\")\n",
    "print(f\"  Typical range (0-60%): {((df_trips_valid['Idle_Percentage'] >= 0) & (df_trips_valid['Idle_Percentage'] <= 60)).sum()} trips ({((df_trips_valid['Idle_Percentage'] >= 0) & (df_trips_valid['Idle_Percentage'] <= 60)).sum() / len(df_trips_valid) * 100:.1f}%)\")\n",
    "print(f\"  High idle (>60%): {(df_trips_valid['Idle_Percentage'] > 60).sum()} trips\")\n",
    "print(f\"  Very high idle (>80%): {(df_trips_valid['Idle_Percentage'] > 80).sum()} trips\")\n",
    "\n",
    "print(f\"\\nTrips requiring investigation (Avg_Speed > 90 or Idle > 80%):\")\n",
    "investigate = df_trips_valid[(df_trips_valid['Avg_Speed_kmh'] > 90) | (df_trips_valid['Idle_Percentage'] > 80)]\n",
    "print(f\"  Total: {len(investigate)} trips\")\n",
    "if len(investigate) > 0:\n",
    "    print(investigate[['vehicle_id', 'Trip_Distance_km', 'Trip_Duration_min', 'Avg_Speed_kmh', 'Idle_Percentage']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fc2d6",
   "metadata": {},
   "source": [
    "## 10. Prepare and Save Consolidated Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602702d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create consolidated cleaned dataset with all relevant columns\n",
    "df_cleaned = df[[\n",
    "    'timestamp_utc', 'vehicle_id', 'engine_on', \n",
    "    'speed_kmh', 'speed_smoothed', 'odometer_km', \n",
    "    'lat', 'lon', 'gps_ok',\n",
    "    'gps_step_km', 'time_delta_hours', 'time_delta_min',\n",
    "    'odo_step_km', 'invalid_odo_step', 'scale_factor',\n",
    "    'fused_step_km', 'distance_missing',\n",
    "    'implied_speed_kmh', 'flagged_over120', 'speeding_over120', 'exclude_from_metrics',\n",
    "    'trip_id', 'trip_key', 'is_idle', 'is_moving'\n",
    "]].copy()\n",
    "\n",
    "# Save the consolidated cleaned dataset\n",
    "output_path = 'data/combined_data_cleaned_pass1.csv'\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Saved {output_path}\")\n",
    "print(f\"  Total rows: {len(df_cleaned):,}\")\n",
    "print(f\"  Total columns: {len(df_cleaned.columns)}\")\n",
    "print(f\"  File size: ~{len(df_cleaned) * len(df_cleaned.columns) * 8 / 1024 / 1024:.1f} MB (estimated)\")\n",
    "\n",
    "# Also save the aggregated dataframes for convenience\n",
    "df_trips_valid.to_csv('data/df_trips.csv', index=False)\n",
    "df_daily.to_csv('data/df_daily.csv', index=False)\n",
    "\n",
    "print(f\"\\n✓ Also saved supplementary files:\")\n",
    "print(f\"  - data/df_trips.csv: {len(df_trips_valid):,} trips\")\n",
    "print(f\"  - data/df_daily.csv: {len(df_daily):,} vehicle-days\")\n",
    "\n",
    "print(\"\\nAll outputs saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display structure of consolidated cleaned data\n",
    "print(\"=\" * 60)\n",
    "print(\"CONSOLIDATED CLEANED DATA STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nColumns in combined_data_cleaned_pass1.csv:\")\n",
    "print(f\"\\nRaw/Original columns:\")\n",
    "print(\"  - timestamp_utc: UTC timestamp\")\n",
    "print(\"  - vehicle_id: Vehicle identifier\")\n",
    "print(\"  - engine_on: Engine status (boolean)\")\n",
    "print(\"  - speed_kmh: Raw speed (km/h)\")\n",
    "print(\"  - odometer_km: Raw odometer reading (km)\")\n",
    "print(\"  - lat, lon: GPS coordinates\")\n",
    "print(\"  - gps_ok: GPS quality indicator\")\n",
    "\n",
    "print(f\"\\nDerived/Engineered columns:\")\n",
    "print(\"  - speed_smoothed: Rolling median smoothed speed\")\n",
    "print(\"  - gps_step_km: Haversine distance between GPS points\")\n",
    "print(\"  - time_delta_hours/min: Time between consecutive points\")\n",
    "print(\"  - odo_step_km: Odometer delta\")\n",
    "print(\"  - invalid_odo_step: Odometer anomaly flag\")\n",
    "print(\"  - scale_factor: GPS-corrected odometer calibration\")\n",
    "print(\"  - fused_step_km: Fused distance (GPS-corrected odo + GPS fallback)\")\n",
    "print(\"  - distance_missing: Flag for missing distance data\")\n",
    "print(\"  - implied_speed_kmh: Speed calculated from distance/time\")\n",
    "print(\"  - flagged_over120: Invalid speeding (bad GPS)\")\n",
    "print(\"  - speeding_over120: Valid speeding (good GPS)\")\n",
    "print(\"  - exclude_from_metrics: Exclusion flag for calculations\")\n",
    "print(\"  - trip_id, trip_key: Trip segmentation identifiers\")\n",
    "print(\"  - is_idle, is_moving: Idle/moving status flags\")\n",
    "\n",
    "print(f\"\\nSample of cleaned data:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd654e3",
   "metadata": {},
   "source": [
    "## 11. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f035152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAFETRUCK DATA CLEANING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nRAW DATA:\")\n",
    "print(f\"  Total rows loaded: {len(df):,}\")\n",
    "print(f\"  Number of vehicles: {df['vehicle_id'].nunique()}\")\n",
    "print(f\"  Date range: {df['timestamp_utc'].min()} to {df['timestamp_utc'].max()}\")\n",
    "\n",
    "print(f\"\\nDATA QUALITY:\")\n",
    "print(f\"  GPS teleports filtered: {teleport_count:,}\")\n",
    "print(f\"  Invalid odometer steps: {df['invalid_odo_step'].sum():,}\")\n",
    "print(f\"  Flagged over 120 (bad GPS): {df['flagged_over120'].sum():,}\")\n",
    "print(f\"  Speeding over 120 (good GPS): {df['speeding_over120'].sum():,}\")\n",
    "print(f\"  Excluded from metrics: {df['exclude_from_metrics'].sum():,}\")\n",
    "\n",
    "print(f\"\\nTRIP SEGMENTATION:\")\n",
    "print(f\"  Total trips identified: {len(df_trips):,}\")\n",
    "print(f\"  Valid trips (≥5 min, ≥1 km): {len(df_trips_valid):,}\")\n",
    "print(f\"  Trips per vehicle (mean): {len(df_trips_valid) / df['vehicle_id'].nunique():.1f}\")\n",
    "\n",
    "print(f\"\\nDISTANCE FUSION:\")\n",
    "print(f\"  Total fused distance: {total_fused_distance:,.2f} km\")\n",
    "print(f\"  From odometer (scaled): {valid_odo_mask.sum():,} segments\")\n",
    "print(f\"  From GPS: {valid_gps_mask.sum():,} segments\")\n",
    "\n",
    "print(f\"\\nTRIP STATISTICS:\")\n",
    "print(f\"  Mean duration: {df_trips_valid['Trip_Duration_min'].mean():.1f} min\")\n",
    "print(f\"  Mean distance: {df_trips_valid['Trip_Distance_km'].mean():.2f} km\")\n",
    "print(f\"  Mean avg speed: {df_trips_valid['Avg_Speed_kmh'].mean():.1f} km/h\")\n",
    "print(f\"  Mean idle %: {df_trips_valid['Idle_Percentage'].mean():.1f}%\")\n",
    "\n",
    "print(f\"\\nDAILY AGGREGATES:\")\n",
    "print(f\"  Vehicle-days: {len(df_daily):,}\")\n",
    "print(f\"  Mean trips/day: {df_daily['Trip_Count'].mean():.1f}\")\n",
    "print(f\"  Mean distance/day: {df_daily['Total_Distance_km'].mean():.1f} km\")\n",
    "print(f\"  Mean duration/day: {df_daily['Total_Duration_min'].mean():.1f} min\")\n",
    "\n",
    "print(f\"\\nOUTPUT FILES:\")\n",
    "print(f\"  combined_data_cleaned_pass1.csv: {len(df_cleaned):,} rows × {len(df_cleaned.columns)} columns\")\n",
    "print(f\"  df_trips.csv: {len(df_trips_valid):,} trips\")\n",
    "print(f\"  df_daily.csv: {len(df_daily):,} vehicle-days\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
